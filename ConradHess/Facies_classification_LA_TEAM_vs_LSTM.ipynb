{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facies classification using Machine Learning #\n",
    "## LA Team Submission 5 ## \n",
    "### _[Lukas Mosser](https://at.linkedin.com/in/lukas-mosser-9948b32b/en), [Alfredo De la Fuente](https://pe.linkedin.com/in/alfredodelafuenteb)_ ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach for solving the facies classfication problem ( https://github.com/seg/2016-ml-contest. ) we will explore the following statregies:\n",
    "- Features Exploration: based on [Paolo Bestagini's work](https://github.com/seg/2016-ml-contest/blob/master/ispl/facies_classification_try02.ipynb), we will consider imputation, normalization and augmentation routines for the initial features.\n",
    "- Model tuning: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "We will need to install the following libraries and packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%sh\n",
    "# pip install pandas\n",
    "# pip install scikit-learn\n",
    "# pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/conrad/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold , StratifiedKFold\n",
    "# from classification_utilities import display_cm, display_adj_cm\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Data\n",
    "data = pd.read_csv('../facies_vectors.csv')\n",
    "# data = pd.read_csv('../ShiangYong/facies_vectors_imputedPE.csv')\n",
    "# Parameters\n",
    "feature_names = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "facies_names = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS', 'WS', 'D', 'PS', 'BS']\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00', '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "\n",
    "# data.dropna(inplace=True)\n",
    "# Store features and labels\n",
    "X = data[feature_names].values \n",
    "y = data['Facies'].values \n",
    "\n",
    "# Store well labels and depths\n",
    "well = data['Well Name'].values\n",
    "depth = data['Depth'].values\n",
    "# X = np.array(pd.DataFrame(X).dropna())\n",
    "# Fill 'PE' missing values with mean\n",
    "imp = preprocessing.Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X)\n",
    "X = imp.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4149 entries, 0 to 4148\n",
      "Data columns (total 11 columns):\n",
      "Facies       4149 non-null int64\n",
      "Formation    4149 non-null object\n",
      "Well Name    4149 non-null object\n",
      "Depth        4149 non-null float64\n",
      "GR           4149 non-null float64\n",
      "ILD_log10    4149 non-null float64\n",
      "DeltaPHI     4149 non-null float64\n",
      "PHIND        4149 non-null float64\n",
      "PE           3232 non-null float64\n",
      "NM_M         4149 non-null int64\n",
      "RELPOS       4149 non-null float64\n",
      "dtypes: float64(7), int64(2), object(2)\n",
      "memory usage: 356.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We procceed to run [Paolo Bestagini's routine](https://github.com/seg/2016-ml-contest/blob/master/ispl/facies_classification_try02.ipynb) to include a small window of values to acount for the spatial component in the log analysis, as well as the gradient information with respect to depth. This will be our prepared training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature windows concatenation function\n",
    "def augment_features_window(X, N_neig):\n",
    "    \n",
    "    # Parameters\n",
    "    N_row = X.shape[0]\n",
    "    N_feat = X.shape[1]\n",
    "\n",
    "    # Zero padding\n",
    "    X = np.vstack((np.zeros((N_neig, N_feat)), X, (np.zeros((N_neig, N_feat)))))\n",
    "\n",
    "    # Loop over windows\n",
    "    X_aug = np.zeros((N_row, N_feat*(2*N_neig+1)))\n",
    "    for r in np.arange(N_row)+N_neig:\n",
    "        this_row = []\n",
    "        for c in np.arange(-N_neig,N_neig+1):\n",
    "            this_row = np.hstack((this_row, X[r+c]))\n",
    "        X_aug[r-N_neig] = this_row\n",
    "\n",
    "    return X_aug\n",
    "\n",
    "\n",
    "# Feature gradient computation function\n",
    "def augment_features_gradient(X, depth):\n",
    "    \n",
    "    # Compute features gradient\n",
    "    d_diff = np.diff(depth).reshape((-1, 1))\n",
    "    d_diff[d_diff==0] = 0.001\n",
    "    X_diff = np.diff(X, axis=0)\n",
    "    X_grad = X_diff / d_diff\n",
    "        \n",
    "    # Compensate for last missing value\n",
    "    X_grad = np.concatenate((X_grad, np.zeros((1, X_grad.shape[1]))))\n",
    "    \n",
    "    return X_grad\n",
    "\n",
    "\n",
    "# Feature augmentation function\n",
    "def augment_features(X, well, depth, N_neig=1):\n",
    "    \n",
    "    # Augment features\n",
    "    X_aug = np.zeros((X.shape[0], X.shape[1]*(N_neig*2+2)))\n",
    "    for w in np.unique(well):\n",
    "        w_idx = np.where(well == w)[0]\n",
    "        X_aug_win = augment_features_window(X[w_idx, :], N_neig)\n",
    "        X_aug_grad = augment_features_gradient(X[w_idx, :], depth[w_idx])\n",
    "        X_aug[w_idx, :] = np.concatenate((X_aug_win, X_aug_grad), axis=1)\n",
    "    \n",
    "    # Find padded rows\n",
    "    padded_rows = np.unique(np.where(X_aug[:, 0:7] == np.zeros((1, 7)))[0])\n",
    "    \n",
    "    return X_aug, padded_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_aug, padded_rows = augment_features(X, well, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Initialize model selection methods\n",
    "# lpgo = LeavePGroupsOut(2)\n",
    "\n",
    "# # Generate splits\n",
    "# split_list = []\n",
    "# for train, val in lpgo.split(X, y, groups=data['Well Name']):\n",
    "#     hist_tr = np.histogram(y[train], bins=np.arange(len(facies_names)+1)+.5)\n",
    "#     hist_val = np.histogram(y[val], bins=np.arange(len(facies_names)+1)+.5)\n",
    "#     if np.all(hist_tr[0] != 0) & np.all(hist_val[0] != 0):\n",
    "#         split_list.append({'train':train, 'val':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    \n",
    "    # Preprocess data to use in model\n",
    "    X_train_aux = []\n",
    "    X_test_aux = []\n",
    "    y_train_aux = []\n",
    "    y_test_aux = []\n",
    "    \n",
    "    # For each data split\n",
    "    split = split_list[5]\n",
    "        \n",
    "    # Remove padded rows\n",
    "    split_train_no_pad = np.setdiff1d(split['train'], padded_rows)\n",
    "\n",
    "    # Select training and validation data from current split\n",
    "    X_tr = X_aug[split_train_no_pad, :]\n",
    "    X_v = X_aug[split['val'], :]\n",
    "    y_tr = y[split_train_no_pad]\n",
    "    y_v = y[split['val']]\n",
    "\n",
    "    # Select well labels for validation data\n",
    "    well_v = well[split['val']]\n",
    "\n",
    "    # Feature normalization\n",
    "    scaler = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_tr)\n",
    "    X_tr = scaler.transform(X_tr)\n",
    "    X_v = scaler.transform(X_v)\n",
    "        \n",
    "    X_train_aux.append( X_tr )\n",
    "    X_test_aux.append( X_v )\n",
    "    y_train_aux.append( y_tr )\n",
    "    y_test_aux.append (  y_v )\n",
    "    \n",
    "    X_train = np.concatenate( X_train_aux )\n",
    "    X_test = np.concatenate ( X_test_aux )\n",
    "    y_train = np.concatenate ( y_train_aux )\n",
    "    y_test = np.concatenate ( y_test_aux )\n",
    "    \n",
    "    return X_train , X_test , y_train , y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "In this section we will run a Cross Validation routine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from tpot import TPOTClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = preprocess()\n",
    "\n",
    "# tpot = TPOTClassifier(generations=5, population_size=20, \n",
    "#                       verbosity=2,max_eval_time_mins=20,\n",
    "#                       max_time_mins=100,scoring='f1_micro',\n",
    "#                       random_state = 17)\n",
    "# tpot.fit(X_train, y_train)\n",
    "# print(tpot.score(X_test, y_test))\n",
    "# tpot.export('FinalPipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conrad/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import  RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import  XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train and test a classifier\n",
    "\n",
    "# Pass in the classifier so we can iterate over many seed later.\n",
    "def train_and_test(X_tr, y_tr, X_v, well_v, clf):\n",
    "    \n",
    "    # Feature normalization\n",
    "    scaler = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_tr)\n",
    "    X_tr = scaler.transform(X_tr)\n",
    "    X_v = scaler.transform(X_v)\n",
    "    \n",
    "    clf.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Test classifier\n",
    "    y_v_hat = clf.predict(X_v)\n",
    "    \n",
    "    # Clean isolated facies for each well\n",
    "    for w in np.unique(well_v):\n",
    "        y_v_hat[well_v==w] = medfilt(y_v_hat[well_v==w], kernel_size=5)\n",
    "    \n",
    "    return y_v_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train and test a classifier\n",
    "\n",
    "# Pass in the classifier so we can iterate over many seed later.\n",
    "def train_and_test_non_validation(X_tr, y_tr, X_v, well_v, clf):\n",
    "    \n",
    "    # Feature normalization\n",
    "    scaler = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_tr)\n",
    "    X_tr = scaler.transform(X_tr)\n",
    "    X_v = scaler.transform(X_v)\n",
    "    \n",
    "    clf.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Test classifier\n",
    "    y_v_hat = clf.predict(X_v)\n",
    "    \n",
    "    # Clean isolated facies for each well\n",
    "#     for w in np.unique(well_v):\n",
    "#         y_v_hat[well_v==w] = medfilt(y_v_hat[well_v==w], kernel_size=5)\n",
    "    \n",
    "    return y_v_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n"
     ]
    }
   ],
   "source": [
    "#Load testing data\n",
    "test_data = pd.read_csv('../validation_data_nofacies.csv')\n",
    "\n",
    "    # Train classifier\n",
    "    #clf = make_pipeline(make_union(VotingClassifier([(\"est\", ExtraTreesClassifier(criterion=\"gini\", max_features=1.0, n_estimators=500))]), FunctionTransformer(lambda X: X)), XGBClassifier(learning_rate=0.73, max_depth=10, min_child_weight=10, n_estimators=500, subsample=0.27))\n",
    "    #clf =  make_pipeline( KNeighborsClassifier(n_neighbors=5, weights=\"distance\") ) \n",
    "    #clf = make_pipeline(MaxAbsScaler(),make_union(VotingClassifier([(\"est\", RandomForestClassifier(n_estimators=500))]), FunctionTransformer(lambda X: X)),ExtraTreesClassifier(criterion=\"entropy\", max_features=0.0001, n_estimators=500))\n",
    "    # * clf = make_pipeline( make_union(VotingClassifier([(\"est\", BernoulliNB(alpha=60.0, binarize=0.26, fit_prior=True))]), FunctionTransformer(lambda X: X)),RandomForestClassifier(n_estimators=500))\n",
    "\n",
    "# # Prepare training data\n",
    "# X_tr = X\n",
    "# y_tr = y\n",
    "\n",
    "# # Augment features\n",
    "# X_tr, padded_rows = augment_features(X_tr, well, depth)\n",
    "\n",
    "# # Removed padded rows\n",
    "# X_tr = np.delete(X_tr, padded_rows, axis=0)\n",
    "# y_tr = np.delete(y_tr, padded_rows, axis=0) \n",
    "\n",
    "# Prepare test data\n",
    "well_ts = test_data['Well Name'].values\n",
    "depth_ts = test_data['Depth'].values\n",
    "X_ts = test_data[feature_names].values\n",
    "\n",
    "\n",
    "    \n",
    "y_pred = []\n",
    "print('.' * 100)\n",
    "for seed in range(3):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Hold out two wells\n",
    "    ind_shk = np.array(data[data['Well Name']=='SHANKLE'].index)\n",
    "    ind_chr = np.array(data[data['Well Name']=='CHURCHMAN BIBLE'].index)\n",
    "    ind_ho_set = np.append(ind_shk,ind_chr)\n",
    "\n",
    "    # Make training data.\n",
    "    X_train, padded_rows = augment_features(X, well, depth)\n",
    "    y_train = y\n",
    "    X_test_nv = np.take(X_train, ind_ho_set, axis=0) \n",
    "    y_test_nv = np.take(y_train, ind_ho_set, axis=0) \n",
    "    X_train_nv = np.delete(X_train, ind_ho_set, axis=0)\n",
    "    y_train_nv = np.delete(y_train, ind_ho_set, axis=0)\n",
    "    \n",
    "    X_train_nv = np.delete(X_train_nv, padded_rows, axis=0)\n",
    "    y_train_nv = np.delete(y_train_nv, padded_rows, axis=0) \n",
    "    \n",
    "    X_test_nv = np.delete(X_test_nv, padded_rows, axis=0)\n",
    "    y_test_nv = np.delete(y_test_nv, padded_rows, axis=0)\n",
    "\n",
    "    # Train classifier  \n",
    "    clf = make_pipeline(XGBClassifier(learning_rate=0.12,\n",
    "                                      max_depth=3,\n",
    "                                      min_child_weight=10,\n",
    "                                      n_estimators=150,\n",
    "                                      seed=seed,\n",
    "                                      colsample_bytree=0.9))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Make blind data.\n",
    "#     X_test, _ = augment_features(X_ts, well_ts, depth_ts)\n",
    "    \n",
    "\n",
    "    # Train and test.\n",
    "#     y_ts_hat = train_and_test(X_train, y_train, X_test, well_ts, clf)\n",
    "    \n",
    "    # Collect result.\n",
    "#     y_pred.append(y_ts_hat)\n",
    "#     print('|', end='')\n",
    "    \n",
    "# np.save('LA_Team_100_realizations.npy', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{937, 3745, 3784}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(padded_rows) & set(ind_ho_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_nv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(853,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_ho_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4149,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train_nv, X_test_nv, y_train_nv, y_test_nv = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "# np.delete(X_train, ind_ho_set, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = train_and_test_non_validation(X_train_nv, y_train_nv, X_test_nv, well_ts, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.571764705882\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "tot = 0\n",
    "for i, entry in enumerate(confusion_matrix(y_pred,y_test_nv)):\n",
    "    for j, e in enumerate(entry):\n",
    "        if i == j:\n",
    "            correct += e\n",
    "        tot += e\n",
    "print(correct/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57176470588235295"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_test_nv, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57176470588235295"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,y_test_nv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attempt at using LSTM for including influence of previous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature windows concatenation function\n",
    "def augment_features_window(X, N_neig):\n",
    "    \n",
    "    # Parameters\n",
    "    N_row = X.shape[0]\n",
    "    N_feat = X.shape[1]\n",
    "\n",
    "    # Zero padding\n",
    "    X = np.vstack((np.zeros((N_neig, N_feat)), X, (np.zeros((N_neig, N_feat)))))\n",
    "\n",
    "    # Loop over windows\n",
    "    X_aug = np.zeros((N_row, (2*N_neig+1), N_feat))\n",
    "    for r in np.arange(N_row)+N_neig:\n",
    "        this_row = []\n",
    "        for c in np.arange(-N_neig,N_neig+1):\n",
    "            this_row = np.hstack((this_row, X[r+c]))\n",
    "#         print(this_row.shape)\n",
    "        this_row.shape = ((2*N_neig+1), this_row.size // (2*N_neig+1))\n",
    "#         print(this_row)\n",
    "        X_aug[r-N_neig] = this_row\n",
    "\n",
    "    return X_aug\n",
    "\n",
    "\n",
    "# Feature augmentation function\n",
    "def augment_features(X, well, depth, N_neig=6):\n",
    "    \n",
    "    # Augment features\n",
    "    X_aug = np.zeros((X.shape[0], (N_neig*2+1), X.shape[1]))\n",
    "    for w in np.unique(well):\n",
    "        w_idx = np.where(well == w)[0]\n",
    "        X_aug_win = augment_features_window(X[w_idx, :], N_neig)\n",
    "#         X_aug_grad = augment_features_gradient(X[w_idx, :], depth[w_idx])\n",
    "        X_aug[w_idx, :] = X_aug_win\n",
    "    \n",
    "    # Find padded rows\n",
    "    padded_rows = np.unique(np.where(X_aug[:, 0:7] == np.zeros((1, 7)))[0])\n",
    "    \n",
    "    return X_aug, padded_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('LSTM_acc_74.h5', overwrite=True)\n",
    "# y_pred = model.predict(X_test_nv_LSTM, batch_size=20, verbose=0)\n",
    "# y_test_LSTM_ct.shape\n",
    "# predicted_classes = np.argmax(y_pred, axis=1)\n",
    "# class_labels = np.argmax(y_test_LSTM_ct, axis=1)\n",
    "# f1_score(predicted_classes,class_labels, average='micro') # micro is the same as accuracy in this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection to apply LSTM w held out well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Data\n",
    "data = pd.read_csv('../facies_vectors.csv')\n",
    "# data = pd.read_csv('../ShiangYong/facies_vectors_imputedPE.csv')\n",
    "# Parameters\n",
    "feature_names = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "facies_names = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS', 'WS', 'D', 'PS', 'BS']\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00', '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "\n",
    "# data.dropna(inplace=True)\n",
    "# Store features and labels\n",
    "X = data[feature_names].values \n",
    "y = data['Facies'].values \n",
    "\n",
    "# Store well labels and depths\n",
    "well = data['Well Name'].values\n",
    "depth = data['Depth'].values\n",
    "# X = np.array(pd.DataFrame(X).dropna())\n",
    "# Fill 'PE' missing values with mean\n",
    "imp = preprocessing.Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X)\n",
    "X = imp.transform(X)\n",
    "\n",
    "# NEEDS TO BE CHANGED, SCALING SHOULD NOT BE DETERMINED FROM TESTING AND TRAINING SET, ONLY TRAINING\n",
    "# scaler = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X)\n",
    "# X = scaler.transform(X)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "# X_test_nv_LSTM = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get indicies of wells that will make up hold out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, padded_rows = augment_features(X, well, depth)\n",
    "y_train = y\n",
    "X_test_LSTM = np.take(X_train, ind_ho_set, axis=0) \n",
    "y_test_LSTM = np.take(y_train, ind_ho_set, axis=0) \n",
    "X_train_LSTM = np.delete(X_train, ind_ho_set, axis=0)\n",
    "y_train_LSTM = np.delete(y_train, ind_ho_set, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4149, 25, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_LSTM = X_test_LSTM[0:840]\n",
    "y_test_LSTM = y_test_LSTM[0:840]\n",
    "X_train_LSTM = X_train_LSTM[0:3280]\n",
    "y_train_LSTM = y_train_LSTM[0:3280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train_nv_LSTM, X_test_nv_LSTM, y_train_nv_LSTM, y_test_nv_LSTM = train_test_split(X_train[0:4000], y_train[0:4000], test_size=0.3, random_state=42)\n",
    "y_train_LSTM = y_train_LSTM - 1\n",
    "y_test_LSTM = y_test_LSTM - 1\n",
    "y_train_LSTM_ct = to_categorical(np.array(y_train_LSTM), num_classes=None)\n",
    "y_test_LSTM_ct = to_categorical(np.array(y_test_LSTM), num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "# Notes\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_dim = 7 # Features\n",
    "timesteps = 25 # 25 is best so far observed\n",
    "num_classes = 9\n",
    "batch_size = 20 # 20 is best so far observed\n",
    "\n",
    "# Expected input batch shape: (batch_size, timesteps, data_dim)\n",
    "# Note that we have to provide the full batch_input_shape since the network is stateful.\n",
    "# the sample of index i in batch k is the follow-up for the sample i in batch k-1.\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(LSTM(40, stateful=True, return_sequences=True,\n",
    "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "\n",
    "# model.add(LSTM(40, return_sequences=True, stateful=True))\n",
    "\n",
    "model.add(LSTM(40, stateful=True))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_LSTM, y_train_LSTM_ct,\n",
    "          batch_size=batch_size, epochs=30, shuffle=False,\n",
    "          validation_data=(X_test_LSTM, y_test_LSTM_ct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Selection to apply LSTM w held out wells from competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "data = pd.read_csv('../facies_vectors.csv')\n",
    "data_valid_labels = pd.read_csv('../blind_stuart_crawford_core_facies.csv')\n",
    "data_valid = pd.read_csv('../validation_data_nofacies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>77.45</td>\n",
       "      <td>0.664</td>\n",
       "      <td>9.9</td>\n",
       "      <td>11.915</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>78.26</td>\n",
       "      <td>0.661</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.565</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.0</td>\n",
       "      <td>79.05</td>\n",
       "      <td>0.658</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13.050</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.5</td>\n",
       "      <td>86.10</td>\n",
       "      <td>0.655</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.115</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>74.58</td>\n",
       "      <td>0.647</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.300</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Facies Formation  Well Name   Depth     GR  ILD_log10  DeltaPHI   PHIND  \\\n",
       "0       3     A1 SH  SHRIMPLIN  2793.0  77.45      0.664       9.9  11.915   \n",
       "1       3     A1 SH  SHRIMPLIN  2793.5  78.26      0.661      14.2  12.565   \n",
       "2       3     A1 SH  SHRIMPLIN  2794.0  79.05      0.658      14.8  13.050   \n",
       "3       3     A1 SH  SHRIMPLIN  2794.5  86.10      0.655      13.9  13.115   \n",
       "4       3     A1 SH  SHRIMPLIN  2795.0  74.58      0.647      13.5  13.300   \n",
       "\n",
       "    PE  NM_M  RELPOS  \n",
       "0  4.6     1   1.000  \n",
       "1  4.1     1   0.979  \n",
       "2  3.6     1   0.957  \n",
       "3  3.5     1   0.936  \n",
       "4  3.4     1   0.915  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>66.276</td>\n",
       "      <td>0.630</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10.65</td>\n",
       "      <td>3.591</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2808.5</td>\n",
       "      <td>77.252</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.95</td>\n",
       "      <td>3.341</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>82.899</td>\n",
       "      <td>0.566</td>\n",
       "      <td>9.4</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.064</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2809.5</td>\n",
       "      <td>80.671</td>\n",
       "      <td>0.593</td>\n",
       "      <td>9.5</td>\n",
       "      <td>13.25</td>\n",
       "      <td>2.977</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>75.971</td>\n",
       "      <td>0.638</td>\n",
       "      <td>8.7</td>\n",
       "      <td>12.35</td>\n",
       "      <td>3.020</td>\n",
       "      <td>1</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Formation Well Name   Depth      GR  ILD_log10  DeltaPHI  PHIND     PE  \\\n",
       "0     A1 SH    STUART  2808.0  66.276      0.630       3.3  10.65  3.591   \n",
       "1     A1 SH    STUART  2808.5  77.252      0.585       6.5  11.95  3.341   \n",
       "2     A1 SH    STUART  2809.0  82.899      0.566       9.4  13.60  3.064   \n",
       "3     A1 SH    STUART  2809.5  80.671      0.593       9.5  13.25  2.977   \n",
       "4     A1 SH    STUART  2810.0  75.971      0.638       8.7  12.35  3.020   \n",
       "\n",
       "   NM_M  RELPOS  \n",
       "0     1   1.000  \n",
       "1     1   0.978  \n",
       "2     1   0.956  \n",
       "3     1   0.933  \n",
       "4     1   0.911  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WellName</th>\n",
       "      <th>Depth.ft</th>\n",
       "      <th>LithCode</th>\n",
       "      <th>LithLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STUART</td>\n",
       "      <td>2807.5</td>\n",
       "      <td>3</td>\n",
       "      <td>NM Shly Silt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STUART</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NM Shly Silt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STUART</td>\n",
       "      <td>2808.5</td>\n",
       "      <td>3</td>\n",
       "      <td>NM Shly Silt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STUART</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NM Shly Silt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STUART</td>\n",
       "      <td>2809.5</td>\n",
       "      <td>3</td>\n",
       "      <td>NM Shly Silt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WellName  Depth.ft  LithCode     LithLabel\n",
       "0   STUART    2807.5         3  NM Shly Silt\n",
       "1   STUART    2808.0         3  NM Shly Silt\n",
       "2   STUART    2808.5         3  NM Shly Silt\n",
       "3   STUART    2809.0         3  NM Shly Silt\n",
       "4   STUART    2809.5         3  NM Shly Silt"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_validation = pd.merge(data_valid, data_valid_labels,  how='left', left_on=['Well Name','Depth'], right_on = ['WellName','Depth.ft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation = data_validation[data_validation.Facies <= 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "      <th>Facies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>66.276</td>\n",
       "      <td>0.630</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10.65</td>\n",
       "      <td>3.591</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2808.5</td>\n",
       "      <td>77.252</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.95</td>\n",
       "      <td>3.341</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>82.899</td>\n",
       "      <td>0.566</td>\n",
       "      <td>9.4</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.064</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2809.5</td>\n",
       "      <td>80.671</td>\n",
       "      <td>0.593</td>\n",
       "      <td>9.5</td>\n",
       "      <td>13.25</td>\n",
       "      <td>2.977</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>75.971</td>\n",
       "      <td>0.638</td>\n",
       "      <td>8.7</td>\n",
       "      <td>12.35</td>\n",
       "      <td>3.020</td>\n",
       "      <td>1</td>\n",
       "      <td>0.911</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Formation Well Name   Depth      GR  ILD_log10  DeltaPHI  PHIND     PE  \\\n",
       "0     A1 SH    STUART  2808.0  66.276      0.630       3.3  10.65  3.591   \n",
       "1     A1 SH    STUART  2808.5  77.252      0.585       6.5  11.95  3.341   \n",
       "2     A1 SH    STUART  2809.0  82.899      0.566       9.4  13.60  3.064   \n",
       "3     A1 SH    STUART  2809.5  80.671      0.593       9.5  13.25  2.977   \n",
       "4     A1 SH    STUART  2810.0  75.971      0.638       8.7  12.35  3.020   \n",
       "\n",
       "   NM_M  RELPOS  Facies  \n",
       "0     1   1.000       3  \n",
       "1     1   0.978       3  \n",
       "2     1   0.956       3  \n",
       "3     1   0.933       3  \n",
       "4     1   0.911       3  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['WellName' 'Depth.ft' 'LithLabel'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-49baa8d2f715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'WellName'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Depth.ft'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'LithLabel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/conrad/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/conrad/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/conrad/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3744\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['WellName' 'Depth.ft' 'LithLabel'] not contained in axis"
     ]
    }
   ],
   "source": [
    "data_validation.drop(['WellName','Depth.ft','LithLabel'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conrad/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3027: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n",
      "/home/conrad/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_validation.rename(columns={\"LithCode\": \"Facies\"}, inplace=True)\n",
    "data_validation.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 800 entries, 0 to 829\n",
      "Data columns (total 11 columns):\n",
      "Formation    800 non-null object\n",
      "Well Name    800 non-null object\n",
      "Depth        800 non-null float64\n",
      "GR           800 non-null float64\n",
      "ILD_log10    800 non-null float64\n",
      "DeltaPHI     800 non-null float64\n",
      "PHIND        800 non-null float64\n",
      "PE           800 non-null float64\n",
      "NM_M         800 non-null int64\n",
      "RELPOS       800 non-null float64\n",
      "Facies       800 non-null int64\n",
      "dtypes: float64(7), int64(2), object(2)\n",
      "memory usage: 75.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data_validation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conrad/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_validation['Facies'] = data_validation['Facies'].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "      <th>Facies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>66.276</td>\n",
       "      <td>0.630</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10.65</td>\n",
       "      <td>3.591</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2808.5</td>\n",
       "      <td>77.252</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.95</td>\n",
       "      <td>3.341</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>82.899</td>\n",
       "      <td>0.566</td>\n",
       "      <td>9.4</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.064</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2809.5</td>\n",
       "      <td>80.671</td>\n",
       "      <td>0.593</td>\n",
       "      <td>9.5</td>\n",
       "      <td>13.25</td>\n",
       "      <td>2.977</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1 SH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>75.971</td>\n",
       "      <td>0.638</td>\n",
       "      <td>8.7</td>\n",
       "      <td>12.35</td>\n",
       "      <td>3.020</td>\n",
       "      <td>1</td>\n",
       "      <td>0.911</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Formation Well Name   Depth      GR  ILD_log10  DeltaPHI  PHIND     PE  \\\n",
       "0     A1 SH    STUART  2808.0  66.276      0.630       3.3  10.65  3.591   \n",
       "1     A1 SH    STUART  2808.5  77.252      0.585       6.5  11.95  3.341   \n",
       "2     A1 SH    STUART  2809.0  82.899      0.566       9.4  13.60  3.064   \n",
       "3     A1 SH    STUART  2809.5  80.671      0.593       9.5  13.25  2.977   \n",
       "4     A1 SH    STUART  2810.0  75.971      0.638       8.7  12.35  3.020   \n",
       "\n",
       "   NM_M  RELPOS  Facies  \n",
       "0     1   1.000       3  \n",
       "1     1   0.978       3  \n",
       "2     1   0.956       3  \n",
       "3     1   0.933       3  \n",
       "4     1   0.911       3  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>77.45</td>\n",
       "      <td>0.664</td>\n",
       "      <td>9.9</td>\n",
       "      <td>11.915</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>78.26</td>\n",
       "      <td>0.661</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.565</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.0</td>\n",
       "      <td>79.05</td>\n",
       "      <td>0.658</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13.050</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.5</td>\n",
       "      <td>86.10</td>\n",
       "      <td>0.655</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.115</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>74.58</td>\n",
       "      <td>0.647</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.300</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Facies Formation  Well Name   Depth     GR  ILD_log10  DeltaPHI   PHIND  \\\n",
       "0       3     A1 SH  SHRIMPLIN  2793.0  77.45      0.664       9.9  11.915   \n",
       "1       3     A1 SH  SHRIMPLIN  2793.5  78.26      0.661      14.2  12.565   \n",
       "2       3     A1 SH  SHRIMPLIN  2794.0  79.05      0.658      14.8  13.050   \n",
       "3       3     A1 SH  SHRIMPLIN  2794.5  86.10      0.655      13.9  13.115   \n",
       "4       3     A1 SH  SHRIMPLIN  2795.0  74.58      0.647      13.5  13.300   \n",
       "\n",
       "    PE  NM_M  RELPOS  \n",
       "0  4.6     1   1.000  \n",
       "1  4.1     1   0.979  \n",
       "2  3.6     1   0.957  \n",
       "3  3.5     1   0.936  \n",
       "4  3.4     1   0.915  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830, 10)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Data\n",
    "# data = pd.read_csv('../facies_vectors.csv')\n",
    "# data_valid_labels = pd.read_csv('../blind_stuart_crawford_core_facies.csv')\n",
    "# data_valid = pd.read_csv('../validation_data_nofacies.csv')\n",
    "# Parameters\n",
    "feature_names = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "facies_names = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS', 'WS', 'D', 'PS', 'BS']\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00', '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "\n",
    "# data.dropna(inplace=True)\n",
    "# Store features and labels\n",
    "X = data[feature_names].values \n",
    "y = data['Facies'].values \n",
    "y_test = data_validation['Facies'].values\n",
    "\n",
    "# Store well labels and depths\n",
    "well = data['Well Name'].values\n",
    "depth = data['Depth'].values\n",
    "# X = np.array(pd.DataFrame(X).dropna())\n",
    "# Fill 'PE' missing values with mean\n",
    "imp = preprocessing.Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X)\n",
    "X = imp.transform(X)\n",
    "\n",
    "# NEEDS TO BE CHANGED, SCALING SHOULD NOT BE DETERMINED FROM TESTING AND TRAINING SET, ONLY TRAINING\n",
    "# scaler = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X)\n",
    "# X = scaler.transform(X)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "# X_test_nv_LSTM = scaler.transform(X)\n",
    "\n",
    "\n",
    "# Repeat process for held out data\n",
    "# data.dropna(inplace=True)\n",
    "# Store features and labels\n",
    "X_ho = data_validation[feature_names].values \n",
    "y_ho = data_validation['Facies'].values \n",
    "\n",
    "# Store well labels and depths\n",
    "well_ho = data_validation['Well Name'].values\n",
    "depth_ho = data_validation['Depth'].values\n",
    "# X = np.array(pd.DataFrame(X).dropna())\n",
    "# Fill 'PE' missing values with mean\n",
    "imp = preprocessing.Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X)\n",
    "X_ho = imp.transform(X_ho)\n",
    "\n",
    "# NEEDS TO BE CHANGED, SCALING SHOULD NOT BE DETERMINED FROM TESTING AND TRAINING SET, ONLY TRAINING\n",
    "# scaler = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X)\n",
    "# X = scaler.transform(X)\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_ho = scaler.transform(X_ho)\n",
    "# X_test_nv_LSTM = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, padded_rows = augment_features(X, well, depth)\n",
    "y_train = y\n",
    "\n",
    "X_test, padded_rows = augment_features(X_ho, well_ho, depth_ho)\n",
    "# y_test = y\n",
    "# X_test_LSTM = np.take(X_train, ind_ho_set, axis=0) \n",
    "# y_test_LSTM = np.take(y_train, ind_ho_set, axis=0) \n",
    "# X_train_LSTM = np.delete(X_train, ind_ho_set, axis=0)\n",
    "# y_train_LSTM = np.delete(y_train, ind_ho_set, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 7)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "well_ho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_ho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4149, 13, 7)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 13, 7)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test[0:800]\n",
    "y_test = y_test[0:800]\n",
    "X_train = X_train[0:4120]\n",
    "y_train = y_train[0:4120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "y_train_ct = to_categorical(np.array(y_train), num_classes=None)\n",
    "y_test_ct = to_categorical(np.array(y_test), num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_15 to have 3 dimensions, but got array with shape (4120, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-b982e06fa67c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m model.fit(X_train, y_train_ct,\n\u001b[1;32m     39\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m           validation_data=(X_test, y_test_ct))\n\u001b[0m",
      "\u001b[0;32m/home/conrad/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/conrad/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1556\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/conrad/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1411\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1414\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1415\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/home/conrad/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_15 to have 3 dimensions, but got array with shape (4120, 8)"
     ]
    }
   ],
   "source": [
    "'''Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "# Notes\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_dim = 7 # Features\n",
    "timesteps = 13 # 25 is best so far observed\n",
    "num_classes = 9\n",
    "batch_size = 20 # 20 is best so far observed\n",
    "\n",
    "# Expected input batch shape: (batch_size, timesteps, data_dim)\n",
    "# Note that we have to provide the full batch_input_shape since the network is stateful.\n",
    "# the sample of index i in batch k is the follow-up for the sample i in batch k-1.\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(LSTM(40, stateful=True, return_sequences=True,\n",
    "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "\n",
    "# model.add(LSTM(40, return_sequences=True, stateful=True))\n",
    "\n",
    "# model.add(LSTM(40, stateful=True))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_ct,\n",
    "          batch_size=batch_size, epochs=30, shuffle=False,\n",
    "          validation_data=(X_test, y_test_ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_validation.Facies).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "      <th>Facies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>A1 LM</td>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3008.5</td>\n",
       "      <td>58.369</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.715</td>\n",
       "      <td>14.235</td>\n",
       "      <td>2.830</td>\n",
       "      <td>2</td>\n",
       "      <td>0.311</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>A1 LM</td>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3009.0</td>\n",
       "      <td>56.125</td>\n",
       "      <td>0.435</td>\n",
       "      <td>-0.775</td>\n",
       "      <td>13.415</td>\n",
       "      <td>2.786</td>\n",
       "      <td>2</td>\n",
       "      <td>0.302</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>A1 LM</td>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3009.5</td>\n",
       "      <td>56.769</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-1.155</td>\n",
       "      <td>12.805</td>\n",
       "      <td>2.726</td>\n",
       "      <td>2</td>\n",
       "      <td>0.292</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>A1 LM</td>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3010.0</td>\n",
       "      <td>62.587</td>\n",
       "      <td>0.298</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>12.870</td>\n",
       "      <td>2.588</td>\n",
       "      <td>2</td>\n",
       "      <td>0.283</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>A1 LM</td>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3010.5</td>\n",
       "      <td>64.674</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.240</td>\n",
       "      <td>14.420</td>\n",
       "      <td>2.465</td>\n",
       "      <td>2</td>\n",
       "      <td>0.274</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>B1 LM</td>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3036.5</td>\n",
       "      <td>62.331</td>\n",
       "      <td>0.834</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>9.835</td>\n",
       "      <td>2.813</td>\n",
       "      <td>2</td>\n",
       "      <td>0.818</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>B1 LM</td>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3037.0</td>\n",
       "      <td>60.946</td>\n",
       "      <td>0.884</td>\n",
       "      <td>-1.690</td>\n",
       "      <td>16.080</td>\n",
       "      <td>2.745</td>\n",
       "      <td>2</td>\n",
       "      <td>0.795</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>B1 LM</td>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3038.0</td>\n",
       "      <td>45.287</td>\n",
       "      <td>0.922</td>\n",
       "      <td>-0.860</td>\n",
       "      <td>18.440</td>\n",
       "      <td>3.962</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>B1 LM</td>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3038.5</td>\n",
       "      <td>30.049</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.445</td>\n",
       "      <td>13.565</td>\n",
       "      <td>4.571</td>\n",
       "      <td>2</td>\n",
       "      <td>0.727</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Formation Well Name   Depth      GR  ILD_log10  DeltaPHI   PHIND     PE  \\\n",
       "546     A1 LM  CRAWFORD  3008.5  58.369      0.504     0.715  14.235  2.830   \n",
       "547     A1 LM  CRAWFORD  3009.0  56.125      0.435    -0.775  13.415  2.786   \n",
       "548     A1 LM  CRAWFORD  3009.5  56.769      0.378    -1.155  12.805  2.726   \n",
       "549     A1 LM  CRAWFORD  3010.0  62.587      0.298    -0.180  12.870  2.588   \n",
       "550     A1 LM  CRAWFORD  3010.5  64.674      0.252     0.240  14.420  2.465   \n",
       "584     B1 LM  CRAWFORD  3036.5  62.331      0.834    -0.245   9.835  2.813   \n",
       "585     B1 LM  CRAWFORD  3037.0  60.946      0.884    -1.690  16.080  2.745   \n",
       "587     B1 LM  CRAWFORD  3038.0  45.287      0.922    -0.860  18.440  3.962   \n",
       "588     B1 LM  CRAWFORD  3038.5  30.049      0.925     0.445  13.565  4.571   \n",
       "\n",
       "     NM_M  RELPOS  Facies  \n",
       "546     2   0.311      11  \n",
       "547     2   0.302      11  \n",
       "548     2   0.292      11  \n",
       "549     2   0.283      11  \n",
       "550     2   0.274      11  \n",
       "584     2   0.818      11  \n",
       "585     2   0.795      11  \n",
       "587     2   0.750      11  \n",
       "588     2   0.727      11  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_validation[data_validation.Facies == 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WellName</th>\n",
       "      <th>Depth.ft</th>\n",
       "      <th>LithCode</th>\n",
       "      <th>LithLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>STUART</td>\n",
       "      <td>2819.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>STUART</td>\n",
       "      <td>2819.5</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>STUART</td>\n",
       "      <td>2820.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>STUART</td>\n",
       "      <td>2820.5</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>STUART</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>STUART</td>\n",
       "      <td>2821.5</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>STUART</td>\n",
       "      <td>2822.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>STUART</td>\n",
       "      <td>2822.5</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3099.5</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3100.5</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3101.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3101.5</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>3102.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NM Sand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WellName  Depth.ft  LithCode LithLabel\n",
       "22     STUART    2819.0         1   NM Sand\n",
       "23     STUART    2819.5         1   NM Sand\n",
       "24     STUART    2820.0         1   NM Sand\n",
       "25     STUART    2820.5         1   NM Sand\n",
       "26     STUART    2821.0         1   NM Sand\n",
       "27     STUART    2821.5         1   NM Sand\n",
       "28     STUART    2822.0         1   NM Sand\n",
       "29     STUART    2822.5         1   NM Sand\n",
       "700  CRAWFORD    3099.5         1   NM Sand\n",
       "701  CRAWFORD    3100.0         1   NM Sand\n",
       "702  CRAWFORD    3100.5         1   NM Sand\n",
       "703  CRAWFORD    3101.0         1   NM Sand\n",
       "704  CRAWFORD    3101.5         1   NM Sand\n",
       "705  CRAWFORD    3102.0         1   NM Sand"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid_labels[data_valid_labels.LithCode == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
